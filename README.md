在这次实验中，我们重点分析损失函数的平滑性对模型的性能影响，并将实验分成两个部分。第一部分，我们用线性层模型模拟一个三次函数，评估样本规模对损失函数的影响，我们发现在相同迭代次数与迭代起点的情况下，我们的样本越大，最后得到的损失值就越小，损失函数平滑度越好。第二部分，我们搭建了不同层数的卷积神经网络，实现了一个图像分类器，分别分析了样本规模和卷积层深度对损失函数的影响，进而得出了其对模型的性能影响，我们发现，更深的层数以及更多的样本，能使模型学习到更多的潜在特征，防止过拟合，达到更好的分类准确率。

实验一：用线性层模型评估样本规模对损失函数的影响



实验二：用卷积神经网络评估样本规模对损失函数的影响
cifar.py 文件用于获取cifar10的图像数据，并将获取的数据放入train_dataset_200或train_dataset_1000中。

NeuralNet.py是卷积神经网络模型的搭建代码

test.py是测试文件，使用train_log中的模型，测试数据在test_dataset中。

Train.py是训练文件，使用train_dataset_200或者train_dataset_1000中的数据，结果记录在train_log中。



